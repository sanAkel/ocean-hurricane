{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanAkel/ocean-hurricane/blob/main/prep_data/download_SAT_retr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose is to Download\n",
        "-  Hurricane data (track, surface pressure, wind) from [tropycal](https://tropycal.github.io/tropycal/install.html).\n",
        "- Data will be gathered from the [CMEMS](https://data.marine.copernicus.eu/products); dataset specific info (may change with dataset, you need to fill it in carefully by looking up CMEMS).\n",
        "- Satellite (retrieved) data:\n",
        "  - [AVISO Sea Surface Height (SSH).](https://data.marine.copernicus.eu/product/SEALEVEL_GLO_PHY_L4_NRT_008_046/services)\n",
        "  - [OSTIA Sea Surface Temperature (SST).](https://data.marine.copernicus.eu/product/SST_GLO_SST_L4_NRT_OBSERVATIONS_010_001/services)\n",
        "  - [CNS Sea Surface Salinity (SSS).](https://data.marine.copernicus.eu/product/MULTIOBS_GLO_PHY_S_SURFACE_MYNRT_015_013/description)\n",
        "  - [GlobCurrent surface currents.](https://data.marine.copernicus.eu/product/MULTIOBS_GLO_PHY_MYNRT_015_003/description)\n",
        "  - [Glob color chlorophyll concentration.](https://data.marine.copernicus.eu/product/OCEANCOLOUR_GLO_BGC_L4_MY_009_104/description)\n",
        "\n",
        "  **Needed inputs**:\n",
        "  1. basin (e.g., `north_atlantic`)\n",
        "  2. year (e.g., `2024`)\n",
        "  3. cat_thr (e.g., `4`)\n",
        "  4. time_delta (e.g., `5`)\n",
        "  5. dLon, dLat (e.g., `5, 5`)\n",
        "  6. List of _priority_ storms, see below."
      ],
      "metadata": {
        "id": "DhJZZA2nCqin"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install modules"
      ],
      "metadata": {
        "id": "fyuPVpzvC3ES"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tropycal\n",
        "!pip install cartopy\n",
        "!pip install copernicusmarine"
      ],
      "metadata": {
        "collapsed": true,
        "id": "UUA1xcHiCtWa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copernicusmarine\n",
        "from tropycal import tracks\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "r5PDxtWWFbxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cmems_data(dsetID, vNames, lon_start, lon_end, lat_start, lat_end, time_start, time_end):\n",
        "\n",
        "  data_request = {\"dataset_id\" : dsetID,\n",
        "    \"longitude\" : [lon_start, lon_end],\n",
        "    \"latitude\" : [lat_start, lat_end],\n",
        "    \"time\" : [time_start, time_end],\n",
        "    \"variables\" : vNames}\n",
        "\n",
        "  cms_data =copernicusmarine.open_dataset(\n",
        "    dataset_id = data_request[\"dataset_id\"],\n",
        "    minimum_longitude = data_request[\"longitude\"][0],\n",
        "    maximum_longitude = data_request[\"longitude\"][1],\n",
        "    minimum_latitude = data_request[\"latitude\"][0],\n",
        "    maximum_latitude = data_request[\"latitude\"][1],\n",
        "    start_datetime = data_request[\"time\"][0],\n",
        "    end_datetime = data_request[\"time\"][1],\n",
        "    variables = data_request[\"variables\"])\n",
        "\n",
        "  return cms_data"
      ],
      "metadata": {
        "id": "3kELja_aJ1zq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CMEMS dataset IDs\n",
        "\n",
        "# AVISO L4 SSH (ADT)/SLA/Geo currents\n",
        "def aviso_l4_ssh(year):\n",
        "\n",
        "  if year < 2022:\n",
        "    dsetID = \"c3s_obs-sl_glo_phy-ssh_my_twosat-l4-duacs-0.25deg_P1D\"\n",
        "    vNames = [\"adt\", \"sla\", \"err_sla\", \"ugos\", \"vgos\"]\n",
        "  else:\n",
        "    dsetID = \"cmems_obs-sl_glo_phy-ssh_nrt_allsat-l4-duacs-0.25deg_P1D\"\n",
        "    vNames = [\"adt\", \"sla\", \"err_sla\", \"ugos\", \"vgos\"]\n",
        "\n",
        "  return dsetID, vNames\n",
        "\n",
        "# OSTIA SST\n",
        "sst={'dsetID':'METOFFICE-GLO-SST-L4-NRT-OBS-SST-V2',\n",
        "     'vNames':['analysed_sst'],\n",
        "     'varName': 'SST'}\n",
        "\n",
        "# CNS SSS NRT\n",
        "sss={'dsetID':'cmems_obs-mob_glo_phy-sss_nrt_multi_P1D',\n",
        "     'vNames':['sos', 'dos'],\n",
        "     'varName': 'SSS'}\n",
        "\n",
        "# GlobCurrent NRT\n",
        "curr={'dsetID':'cmems_obs-mob_glo_phy-cur_nrt_0.25deg_P1D-m',\n",
        "     'vNames':['uo', 'vo'],\n",
        "     'varName': 'CURRENT'}\n",
        "\n",
        "# GlobColor\n",
        "chla={'dsetID':'cmems_obs-oc_glo_bgc-plankton_my_l4-gapfree-multi-4km_P1D',\n",
        "      'vNames':['CHL'],\n",
        "      'varName': 'CHLa'}"
      ],
      "metadata": {
        "id": "wpRe9KPQKfX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inputs"
      ],
      "metadata": {
        "id": "HygT4GyeEpcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myBasin = 'north_atlantic' # basin\n",
        "year = 2024 # year\n",
        "cat_thr = 4 # ignore hurricanes below this threshold.\n",
        "time_delta = 5 # days before/after storm\n",
        "dLon, dLat = [5, 5] # plot extra data outside track bounds (in degrees)"
      ],
      "metadata": {
        "id": "jot-GmXqErAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# List of storms (highlighted are _priority_) are from: https://docs.google.com/spreadsheets/d/1iXmzHsz0liWpJKxDz_KR1-hwW-FPzLLYF4hFvw7m1t4/edit?usp=sharing\n",
        "# Thanks to zhan.zhang@noaa.gov\n",
        "# Added a few extra ones (open ocean). Kirk (2024); Franklin (2023), Lee (2023)\n",
        "\n",
        "if year == 2024:\n",
        "  pr_st = [\"oscar\", \"milton\", \"helene\", \"francine\", \"ernesto\", \"debby\", \"beryl\", \"kirk\"]\n",
        "elif year == 2023:\n",
        "  pr_st = [\"philippe\", \"ophelia\", \"nigel\", \"idalia\", \"gert p2\", \"gert p1\", \"don p2\", \"don p1\", \"bret\", \"franklin\", \"lee\"]\n",
        "elif year == 2022:\n",
        "  pr_st = [\"nicole\", \"ian\", \"gaston\", \"fiona\", \"earl\", \"danielle\"]\n",
        "else:\n",
        "  print(\"List of priority storms not yet coded for year:\\t {}\"%format(year))"
      ],
      "metadata": {
        "id": "aWNXOhTkGVW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to save data:\n",
        "dPath = f'data/{myBasin}/{year}/'\n",
        "!mkdir -p $dPath\n",
        "print(dPath)"
      ],
      "metadata": {
        "id": "c8TydqpHGNYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download hurricane track data (entire chosen `year`)"
      ],
      "metadata": {
        "id": "AwJD15uJFFfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "# https://tropycal.github.io/tropycal/api/generated/tropycal.tracks.TrackDataset.html#tropycal.tracks.TrackDataset\n",
        "\n",
        "basin = tracks.TrackDataset(basin=myBasin, source='hurdat', include_btk=True)\n",
        "season = basin.get_season(year)\n",
        "print(f'Downloading data for...{season}')\n",
        "\n",
        "# save data\n",
        "season_data=season.to_dataframe()\n",
        "fName = dPath + 'hurdat2_{}_{}.csv'.format(myBasin, year)\n",
        "season_data.to_csv(fName)\n",
        "print(f'Saved to hurricane track data:\\t{fName}')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dNr5DcvUE-W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Copernicus credentials\n",
        "CMEMS_username, CMEMS_passwd = [\"sakella\", \"HbFPyP9M\"]\n",
        "copernicusmarine.login(username=CMEMS_username, password=CMEMS_passwd)"
      ],
      "metadata": {
        "id": "lsHEyH2YKqLh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hurr_names = season_data['name']\n",
        "hurr_ids = season_data['id']\n",
        "\n",
        "for idx, hurr_id in enumerate(hurr_ids):\n",
        "  if hurr_names.iloc[idx].lower() in pr_st:\n",
        "    print(f'{hurr_names.iloc[idx]} was listed as a priority storm.')"
      ],
      "metadata": {
        "id": "q__J_GNfJSTO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Focus on _priority_ storms (as defined above) only."
      ],
      "metadata": {
        "id": "4rXXpIqeIFMx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hurr_names = season_data['name']\n",
        "hurr_ids = season_data['id']\n",
        "\n",
        "print(\"\\n\\nGathering details of following storms:\\n\")\n",
        "for idx, hurr_id in enumerate(hurr_ids):\n",
        "    if hurr_names.iloc[idx].lower() in pr_st:\n",
        "      print(\"\\nDownload and saving...\\t{}, [{}]\".format(hurr_names.iloc[idx], hurr_id))\n",
        "      hurr=basin.get_storm(hurr_id)\n",
        "      # Hurricane formation and dissipation dates (yyyymmdd)\n",
        "      print(\"Formed on: {},\\t dissipated on: {}\".\n",
        "      format(hurr.time[0].strftime('%Y-%m-%d'), hurr.time[-1].strftime('%Y-%m-%d')))\n",
        "      t0 = hurr.time[0] - pd.Timedelta(days=time_delta)\n",
        "      t1 = hurr.time[-1] + pd.Timedelta(days=time_delta)\n",
        "\n",
        "      storm_fName = str(year) + \"_\" + myBasin + \"_\" + hurr_names.iloc[idx] + '.nc'\n",
        "      track_file = dPath + storm_fName\n",
        "      hurr.to_xarray().to_netcdf(track_file)\n",
        "      print(\"Saved track info to:\\n{}\".format(track_file))\n",
        "\n",
        "      # Read back the saved data (for formatting) and use it here onward\n",
        "      hurr=xr.open_dataset(track_file)\n",
        "\n",
        "      # download SSH data, nuanced than other datasets- needs special treatment\n",
        "      ssh_data = get_cmems_data(*aviso_l4_ssh(year),\n",
        "                        hurr.lon.values.min()-dLon, hurr.lon.values.max()+dLon,\n",
        "                        hurr.lat.values.min()-dLat, hurr.lat.values.max()+dLat,\n",
        "                        t0.strftime('%Y-%m-%d'), t1.strftime('%Y-%m-%d'))\n",
        "\n",
        "      # add geostrophic currents to the dataset- eases our life!\n",
        "      ssh_data['surf_curr'] = xr.DataArray(np.sqrt(ssh_data.ugos**2 + ssh_data.vgos**2),\\\n",
        "                                         coords=ssh_data.ugos.coords,\n",
        "                                         dims=ssh_data.ugos.dims,\n",
        "                                         name='surf_curr',\n",
        "                                         attrs={'units':'m/s'})\n",
        "\n",
        "      ssh_data_file = dPath +\\\n",
        "      'AVISO_' + str(year)+'_'+hurr_names.iloc[idx]+'.nc'\n",
        "      ssh_data.to_netcdf(ssh_data_file)\n",
        "      print(\"\\nSaved SSH data to:\\n{}\".format(ssh_data_file))\n",
        "\n",
        "      # download other datasets\n",
        "      for dtype in [sst, sss, curr, chla]:\n",
        "        sat_data = get_cmems_data(dtype['dsetID'], dtype['vNames'],\n",
        "                        hurr.lon.values.min()-dLon, hurr.lon.values.max()+dLon,\n",
        "                        hurr.lat.values.min()-dLat, hurr.lat.values.max()+dLat,\n",
        "                        t0.strftime('%Y-%m-%d'), t1.strftime('%Y-%m-%d'))\n",
        "\n",
        "        sat_data_file = dPath +\\\n",
        "                      dtype['varName'] +'_'+\\\n",
        "                      str(year)+'_'+hurr_names.iloc[idx]+'.nc'\n",
        "        sat_data.to_netcdf(sat_data_file)\n",
        "        print(\"\\nSaved {} data to:\\n{}\".format(dtype['varName'],sat_data_file))"
      ],
      "metadata": {
        "id": "BpHSpBk9G0uW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save to drive"
      ],
      "metadata": {
        "id": "JQf6AsJ6FN-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!mkdir -p /content/drive/MyDrive/datasets/hurr/$myBasin/$year/\n",
        "!mv $dPath/* /content/drive/MyDrive/datasets/hurr/$myBasin/$year/"
      ],
      "metadata": {
        "id": "TvwgzmEkDTTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "avq6BEU2FMNH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}