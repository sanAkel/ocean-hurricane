{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTvu5uSA42iPyqO+vTbB4W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanAkel/ocean-hurricane/blob/main/prep_data/download_surf_GLORYS12.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Purpose is to Download\n",
        "-  Hurricane data (track, surface pressure, wind) from [tropycal](https://tropycal.github.io/tropycal/install.html).\n",
        "- [Ocean-reanalysis data from GLorys12](https://data.marine.copernicus.eu/product/GLOBAL_ANALYSISFORECAST_PHY_001_024/services) will be gathered from the [CMEMS](https://data.marine.copernicus.eu/products); dataset specific info (may change with dataset, you need to fill it in carefully by looking up CMEMS).\n",
        "\n",
        "\n",
        "  **Needed inputs**:\n",
        "  1. basin (e.g., `north_atlantic`)\n",
        "  2. year (e.g., `2024`)\n",
        "  4. time_delta (e.g., `5`)\n",
        "  5. dLon, dLat (e.g., `5, 5`)\n",
        "  6. List of _priority_ storms, see below."
      ],
      "metadata": {
        "id": "OzSXOcMiWueu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install modules"
      ],
      "metadata": {
        "id": "xERqfWuWXUJt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tropycal\n",
        "!pip install cartopy\n",
        "!pip install copernicusmarine"
      ],
      "metadata": {
        "id": "AS_1M2paXOAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copernicusmarine\n",
        "from tropycal import tracks\n",
        "import xarray as xr\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "2pHTFrAFXXPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_cmems_data(dsetID, vNames, lon_start, lon_end, lat_start, lat_end, time_start, time_end):\n",
        "\n",
        "  data_request = {\"dataset_id\" : dsetID,\n",
        "    \"longitude\" : [lon_start, lon_end],\n",
        "    \"latitude\" : [lat_start, lat_end],\n",
        "    \"time\" : [time_start, time_end],\n",
        "    \"variables\" : vNames}\n",
        "\n",
        "  cms_data =copernicusmarine.open_dataset(\n",
        "    dataset_id = data_request[\"dataset_id\"],\n",
        "    minimum_longitude = data_request[\"longitude\"][0],\n",
        "    maximum_longitude = data_request[\"longitude\"][1],\n",
        "    minimum_latitude = data_request[\"latitude\"][0],\n",
        "    maximum_latitude = data_request[\"latitude\"][1],\n",
        "    start_datetime = data_request[\"time\"][0],\n",
        "    end_datetime = data_request[\"time\"][1],\n",
        "    variables = data_request[\"variables\"])\n",
        "\n",
        "  return cms_data"
      ],
      "metadata": {
        "id": "vyvm9H9pXf_Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### User Inputs"
      ],
      "metadata": {
        "id": "O_0DNe8aXn_l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myBasin = 'north_atlantic' # basin\n",
        "year = 2024 # year\n",
        "time_delta = 5 # days before/after storm\n",
        "dLon, dLat = [5, 5] # plot extra data outside track bounds (in degrees)\n",
        "\n",
        "# List of _priority_ storms.\n",
        "# Added a few extra ones (open ocean). Kirk (2024); Franklin (2023), Lee (2023)\n",
        "\n",
        "if year == 2024:\n",
        "  pr_st = [\"oscar\", \"milton\", \"helene\", \"francine\", \"ernesto\", \"debby\", \"beryl\", \"kirk\"]\n",
        "elif year == 2023:\n",
        "  pr_st = [\"philippe\", \"ophelia\", \"nigel\", \"idalia\", \"gert p2\", \"gert p1\", \"don p2\", \"don p1\", \"bret\", \"franklin\", \"lee\"]\n",
        "elif year == 2022:\n",
        "  pr_st = [\"nicole\", \"ian\", \"gaston\", \"fiona\", \"earl\", \"danielle\"]\n",
        "else:\n",
        "  print(\"List of priority storms not yet coded for year:\\t {}\"%format(year))"
      ],
      "metadata": {
        "id": "_N3jcQc-Xj3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to save data:\n",
        "dPath = f'data/{myBasin}/{year}/'\n",
        "!mkdir -p $dPath\n",
        "print(dPath)"
      ],
      "metadata": {
        "id": "dhtBFowpX1Hy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Download hurricane track data (entire chosen `year`)"
      ],
      "metadata": {
        "id": "anjhjE83X984"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize\n",
        "# https://tropycal.github.io/tropycal/api/generated/tropycal.tracks.TrackDataset.html#tropycal.tracks.TrackDataset\n",
        "\n",
        "basin = tracks.TrackDataset(basin=myBasin, source='hurdat', include_btk=True)\n",
        "season = basin.get_season(year)\n",
        "print(f'Downloading data for...{season}')\n",
        "\n",
        "# save data\n",
        "season_data=season.to_dataframe()\n",
        "fName = dPath + 'hurdat2_{}_{}.csv'.format(myBasin, year)\n",
        "season_data.to_csv(fName)\n",
        "print(f'Saved to hurricane track data:\\t{fName}')"
      ],
      "metadata": {
        "id": "N20nvtzpX4Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set Copernicus credentials\n",
        "CMEMS_username, CMEMS_passwd = [\"sakella\", \"HbFPyP9M\"]\n",
        "copernicusmarine.login(username=CMEMS_username, password=CMEMS_passwd)"
      ],
      "metadata": {
        "id": "YcsEfbrOX7B1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CMEMS dataset IDs - Reanalysis GLORYS12\n",
        "# https://catalogue.marine.copernicus.eu/documents/PUM/CMEMS-GLO-PUM-001-024.pdf\n",
        "# Hourly mean surface (2d) fields: cmems_mod_glo_phy_anfc_0.083deg_PT1H-m\n",
        "\n",
        "dset_oras = \"cmems_mod_glo_phy_anfc_0.083deg_PT1H-m\"\n",
        "vars_gloys12 = [\"zos\", \"so\", \"thetao\", \"uo\", \"vo\"]\n",
        "vNames = [\"SSH\", \"SSS\", \"SST\", \"SSU\", \"SSV\"]"
      ],
      "metadata": {
        "id": "_wSKG0rcYQ19"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Focus on _priority_ storms (as defined above) only."
      ],
      "metadata": {
        "id": "mKj6AbRCYJjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hurr_names = season_data['name']\n",
        "hurr_ids = season_data['id']\n",
        "\n",
        "print(\"\\nDownloading GLORYS12 data for the following storms:\\n\")\n",
        "for idx, hurr_id in enumerate(hurr_ids):\n",
        "    hurr_name = hurr_names.iloc[idx]\n",
        "    if hurr_names.iloc[idx].lower() in pr_st:\n",
        "      print(\"\\nHurricane...\\t{}, [{}]\".format(hurr_name, hurr_id))\n",
        "      hurr=basin.get_storm(hurr_id)\n",
        "      # Hurricane formation and dissipation dates (yyyymmdd)\n",
        "      print(\"Formed on: {},\\t dissipated on: {}\".\n",
        "      format(hurr.time[0].strftime('%Y-%m-%d'), hurr.time[-1].strftime('%Y-%m-%d')))\n",
        "      t0 = hurr.time[0] - pd.Timedelta(days=time_delta)\n",
        "      t1 = hurr.time[-1] + pd.Timedelta(days=time_delta)\n",
        "\n",
        "      storm_fName = str(year) + \"_\" + myBasin + \"_\" + hurr_name + '.nc'\n",
        "      track_file = dPath + storm_fName\n",
        "      hurr.to_xarray().to_netcdf(track_file)\n",
        "      print(\"Saved track info to:\\n{}\".format(track_file))\n",
        "\n",
        "      # Read back the saved data (for formatting) and use it here onward\n",
        "      hurr=xr.open_dataset(track_file)\n",
        "\n",
        "      lon_s, lon_e = [hurr.lon.values.min()-dLon, hurr.lon.values.max()+dLon]\n",
        "      lat_s, lat_e = [hurr.lat.values.min()-dLat, hurr.lat.values.max()+dLat]\n",
        "      t_s, t_e = [t0.strftime('%Y-%m-%d'), t1.strftime('%Y-%m-%d')]\n",
        "      !mkdir -p $dPath/$hurr_name\n",
        "\n",
        "      # download GLORYS12 datasets\n",
        "      for vid, vName in enumerate(vNames):\n",
        "        print(\"Downloading:\\t{}\".format(vName))\n",
        "        oras_data_path = dPath +  hurr_name + '/'+'GLO12_'+ vName + '_' +str(year)+'_'+hurr_name\n",
        "        var_oras = vars_gloys12[vid]\n",
        "        print(var_oras, oras_data_path)\n",
        "        !copernicusmarine subset --dataset-id $dset_oras --username $CMEMS_username --password $CMEMS_passwd -o $oras_data_path --variable $var_oras --minimum-latitude $lat_s --maximum-latitude $lat_e --minimum-longitude $lon_s --maximum-longitude $lon_e --start-datetime $t_s --end-datetime $t_e --service arco-geo-series\n",
        "      !tar -cvf $hurr_name+'.tar' $dPath+$hurr_name+'/*'\n",
        "      !rm -rf $dPath+$hurr_name+'/'"
      ],
      "metadata": {
        "id": "VqnadcsuYGSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Size of datasets > 15GB that is available on _unpaid_ account."
      ],
      "metadata": {
        "id": "S5jlwJKKduyA"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nGKOz1OCdwCg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}